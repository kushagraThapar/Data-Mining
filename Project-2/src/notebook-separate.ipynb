{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from time import time\n",
    "import string\n",
    "import itertools\n",
    "from html import unescape\n",
    "import preprocessor as p\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "from sklearn import cross_validation\n",
    "from sklearn import svm\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data from Excel file and create data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_excel_file(filename, sheetname):\n",
    "    return pd.read_excel(filename, sheetname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_unwanted_columns(tweet_df):\n",
    "    del tweet_df['date']\n",
    "    del tweet_df['time']\n",
    "    return tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_from_input_data (filename):\n",
    "    tweet_df_obama = read_excel_file(filename, 0)\n",
    "    tweet_df_romney = read_excel_file(filename, 1)\n",
    "    # tweet_df_obama = remove_unwanted_columns(tweet_df_obama)\n",
    "    # tweet_df_romney = remove_unwanted_columns(tweet_df_romney)\n",
    "    \n",
    "    tweet_df_obama['Class'] = tweet_df_obama['Class'].astype('str').map(lambda x: x.lstrip(' ').rstrip(' '))\n",
    "    tweet_df_obama['Class'] = tweet_df_obama['Class'].astype('str').map(lambda x: x.replace('!!!!', ''))\n",
    "    \n",
    "    tweet_data_df_obama = tweet_df_obama.loc[tweet_df_obama.Class=='1'].append(tweet_df_obama.loc[tweet_df_obama.Class=='-1']).append(tweet_df_obama.loc[tweet_df_obama.Class=='0'])\n",
    "    \n",
    "    tweet_data_df_obama.dropna(inplace = True)\n",
    "    \n",
    "    tweet_df_romney['Class'] = tweet_df_romney['Class'].astype('str').map(lambda x: x.lstrip(' ').rstrip(' '))\n",
    "    tweet_df_romney['Class'] = tweet_df_romney['Class'].astype('str').map(lambda x: x.replace('!!!!', ''))\n",
    "    \n",
    "    tweet_data_df_romney = tweet_df_romney.loc[tweet_df_romney.Class=='1'].append(tweet_df_romney.loc[tweet_df_romney.Class=='-1']).append(tweet_df_romney.loc[tweet_df_romney.Class=='0'])\n",
    "    \n",
    "    tweet_data_df_romney.dropna(inplace = True)\n",
    "    \n",
    "    return tweet_data_df_obama, tweet_data_df_romney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_training_data(df, train_data_prcnt):\n",
    "    msk = np.random.rand(len(df)) < train_data_prcnt/100\n",
    "    train = df[msk]\n",
    "    test = df[~msk]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweet_df_obama, tweet_df_romney = read_from_input_data(\"training-Obama-Romney-tweets.xlsx\")\n",
    "exclude = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama Data\n",
      "-1 : 1968\n",
      " 1 : 1679\n",
      " 0 : 1977\n",
      "\n",
      "Romney Data\n",
      "-1 : 2893\n",
      " 1 : 1075\n",
      " 0 : 1680\n"
     ]
    }
   ],
   "source": [
    "print(\"Obama Data\")\n",
    "print(\"-1 : \" + str(len(tweet_df_obama.loc[tweet_df_obama.Class=='-1'])))\n",
    "print(\" 1 : \" + str(len(tweet_df_obama.loc[tweet_df_obama.Class=='1'])))\n",
    "print(\" 0 : \" + str(len(tweet_df_obama.loc[tweet_df_obama.Class=='0'])))\n",
    "\n",
    "print(\"\\nRomney Data\")\n",
    "\n",
    "print(\"-1 : \" + str(len(tweet_df_romney.loc[tweet_df_romney.Class=='-1'])))\n",
    "print(\" 1 : \" + str(len(tweet_df_romney.loc[tweet_df_romney.Class=='1'])))\n",
    "print(\" 0 : \" + str(len(tweet_df_romney.loc[tweet_df_romney.Class=='0'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_tweet_text(text):\n",
    "    \n",
    "    if not pd.isnull(text):\n",
    "        # Remove html escape characters and replace with their meaning\n",
    "        text = unescape(text)\n",
    "        # Decode tweet to utf-8 format\n",
    "\n",
    "        text = text.encode(\"ascii\", \"ignore\").decode(\"utf8\")\n",
    "\n",
    "        # Clean data using tweet preprocessor and convert to lower case\n",
    "        text = str.lower(p.clean(text))\n",
    "\n",
    "        # Remove characters\n",
    "        text = text.replace(\"<e>\", \"\")\n",
    "        text = text.replace(\"</e>\", \"\")\n",
    "        text = text.replace(\"<a>\", \"\")\n",
    "        text = text.replace(\"</a>\", \"\")\n",
    "\n",
    "        # Remove multiple repetition of a character in word\n",
    "        text = ''.join(''.join(s)[:2] for _, s in itertools.groupby(text))\n",
    "\n",
    "        # Remove punctuation\n",
    "        text = ''.join(ch for ch in text if ch not in exclude)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweet_df_obama['Anootated tweet'] = tweet_df_obama['Anootated tweet'].map(clean_tweet_text)\n",
    "tweet_df_romney['Anootated tweet'] = tweet_df_romney['Anootated tweet'].map(clean_tweet_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slipt data into train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4281\n",
      "1343\n",
      "4264\n",
      "1384\n"
     ]
    }
   ],
   "source": [
    "tweet_random_df_obama = tweet_df_obama.copy()\n",
    "\n",
    "for i in range(0, 500):\n",
    "    split1_df, split2_df = split_training_data(tweet_random_df_obama, 50)\n",
    "    tweet_random_df_obama = pd.concat([split1_df, split2_df])\n",
    "\n",
    "train_df_obama, test_df_obama = split_training_data(tweet_random_df_obama, 75)\n",
    "\n",
    "print(len(train_df_obama))\n",
    "print(len(test_df_obama))\n",
    "\n",
    "tweet_random_df_romney = tweet_df_romney.copy()\n",
    "\n",
    "for i in range(0, 500):\n",
    "    split1_df, split2_df = split_training_data(tweet_random_df_romney, 50)\n",
    "    tweet_random_df_romney = pd.concat([split1_df, split2_df])\n",
    "\n",
    "train_df_romney, test_df_romney = split_training_data(tweet_random_df_romney, 75)\n",
    "\n",
    "print(len(train_df_romney))\n",
    "print(len(test_df_romney))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Bag of Words model to sparce vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(stop_words='english', max_features=2000 )\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english', max_features=2000)\n",
    "hash_vectorizer = HashingVectorizer(stop_words='english', non_negative=True, n_features = 2000)\n",
    "tfidf_transformer = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_counts_obama = count_vect.fit_transform(train_df_obama['Anootated tweet'])\n",
    "X_test_counts_obama = count_vect.transform(test_df_obama['Anootated tweet'])\n",
    "\n",
    "X_train_obama = tfidf_transformer.fit_transform(X_train_counts_obama)\n",
    "X_test_obama = tfidf_transformer.transform(X_test_counts_obama)\n",
    "\n",
    "y_train_obama = train_df_obama['Class']\n",
    "y_test_obama = test_df_obama['Class']\n",
    "\n",
    "\n",
    "X_train_counts_romney = count_vect.fit_transform(train_df_romney['Anootated tweet'])\n",
    "X_test_counts_romney = count_vect.transform(test_df_romney['Anootated tweet'])\n",
    "\n",
    "X_train_romney = tfidf_transformer.fit_transform(X_train_counts_romney)\n",
    "X_test_romney = tfidf_transformer.transform(X_test_counts_romney)\n",
    "\n",
    "y_train_romney = train_df_romney['Class']\n",
    "y_test_romney = test_df_romney['Class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trim(s):\n",
    "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
    "    return s if len(s) <= 80 else s[:77] + \"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Classification function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pipeline_function(clf, X_train, X_test, y_train, y_test, categories):\n",
    "    print('*' * 60)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "\n",
    "#         if feature_names is not None:\n",
    "#             print(\"top 10 keywords per class:\")\n",
    "#             for i, category in enumerate(categories):\n",
    "#                 top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "#                 print(trim(\"%s: %s\"\n",
    "#                       % (category, \" \".join(feature_names[top10]))))\n",
    "#         print()\n",
    "\n",
    "    print(\"classification report:\")\n",
    "    print(metrics.classification_report(y_test, pred,\n",
    "                                        target_names=categories))\n",
    "\n",
    "    print(\"confusion matrix:\")\n",
    "    print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    return clf_descr, score, train_time, test_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "Naive Bayes Obama\n",
      "************************************************************\n",
      "Training: \n",
      "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "train time: 0.015s\n",
      "test time:  0.000s\n",
      "accuracy:   0.561\n",
      "dimensionality: 2000\n",
      "density: 1.000000\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.58      0.64      0.61       488\n",
      "          0       0.51      0.45      0.48       457\n",
      "          1       0.58      0.59      0.59       398\n",
      "\n",
      "avg / total       0.56      0.56      0.56      1343\n",
      "\n",
      "confusion matrix:\n",
      "[[313 112  63]\n",
      " [145 205 107]\n",
      " [ 81  82 235]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "categories_obama = np.unique(y_train_obama.values)\n",
    "# Train sparse Naive Bayes classifiers\n",
    "print('*' * 60)\n",
    "print(\"Naive Bayes Obama\")\n",
    "results.append(pipeline_function(MultinomialNB(alpha=.01), \n",
    "                                 X_train_obama, X_test_obama, \n",
    "                                 y_train_obama, y_test_obama, \n",
    "                                 categories_obama))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "Naive Bayes Romney\n",
      "************************************************************\n",
      "Training: \n",
      "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "train time: 0.013s\n",
      "test time:  0.000s\n",
      "accuracy:   0.569\n",
      "dimensionality: 2000\n",
      "density: 1.000000\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.61      0.80      0.69       716\n",
      "          0       0.46      0.32      0.37       403\n",
      "          1       0.52      0.34      0.41       265\n",
      "\n",
      "avg / total       0.55      0.57      0.54      1384\n",
      "\n",
      "confusion matrix:\n",
      "[[570 108  38]\n",
      " [231 127  45]\n",
      " [133  42  90]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "categories_romney = np.unique(y_train_romney.values)\n",
    "# Train sparse Naive Bayes classifiers\n",
    "print('*' * 60)\n",
    "print(\"Naive Bayes Romney\")\n",
    "results.append(pipeline_function(MultinomialNB(alpha=.01), \n",
    "                                 X_train_romney, X_test_romney, \n",
    "                                 y_train_romney, y_test_romney, \n",
    "                                 categories_romney))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbour Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "k Nearest Neighbour Obama\n",
      "************************************************************\n",
      "Training: \n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "train time: 0.006s\n",
      "test time:  0.498s\n",
      "accuracy:   0.444\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.67      0.23      0.35       488\n",
      "          0       0.47      0.39      0.43       457\n",
      "          1       0.38      0.76      0.51       398\n",
      "\n",
      "avg / total       0.52      0.44      0.42      1343\n",
      "\n",
      "confusion matrix:\n",
      "[[114 124 250]\n",
      " [ 36 178 243]\n",
      " [ 21  73 304]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train k-Nearest Neighbour classifiers\n",
    "results = []\n",
    "print('*' * 60)\n",
    "print(\"k Nearest Neighbour Obama\")\n",
    "results.append(pipeline_function(KNeighborsClassifier(n_neighbors=10, n_jobs = -1), \n",
    "                                 X_train_obama, X_test_obama, \n",
    "                                 y_train_obama, y_test_obama, \n",
    "                                 categories_obama))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "k Nearest Neighbour Romney\n",
      "************************************************************\n",
      "Training: \n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "train time: 0.005s\n",
      "test time:  0.500s\n",
      "accuracy:   0.363\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.65      0.17      0.27       716\n",
      "          0       0.30      0.86      0.45       403\n",
      "          1       0.62      0.14      0.22       265\n",
      "\n",
      "avg / total       0.54      0.36      0.31      1384\n",
      "\n",
      "confusion matrix:\n",
      "[[121 582  13]\n",
      " [ 49 345   9]\n",
      " [ 16 213  36]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "print('*' * 60)\n",
    "print(\"k Nearest Neighbour Romney\")\n",
    "results.append(pipeline_function(KNeighborsClassifier(n_neighbors=10, n_jobs = -1), \n",
    "                                 X_train_romney, X_test_romney, \n",
    "                                 y_train_romney, y_test_romney, \n",
    "                                 categories_romney))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Random Forest Obama\n",
      "************************************************************\n",
      "Training: \n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "train time: 2.454s\n",
      "test time:  0.075s\n",
      "accuracy:   0.553\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.63      0.53      0.58       488\n",
      "          0       0.48      0.61      0.54       457\n",
      "          1       0.58      0.51      0.54       398\n",
      "\n",
      "avg / total       0.56      0.55      0.55      1343\n",
      "\n",
      "confusion matrix:\n",
      "[[260 166  62]\n",
      " [ 89 280  88]\n",
      " [ 63 132 203]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest classifiers\n",
    "results = []\n",
    "print('=' * 80)\n",
    "print(\"Random Forest Obama\")\n",
    "results.append(pipeline_function(RandomForestClassifier(n_estimators=100), \n",
    "                                 X_train_obama, X_test_obama, \n",
    "                                 y_train_obama, y_test_obama, \n",
    "                                 categories_obama))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Random Forest Romney\n",
      "************************************************************\n",
      "Training: \n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "train time: 2.720s\n",
      "test time:  0.108s\n",
      "accuracy:   0.547\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.59      0.79      0.68       716\n",
      "          0       0.43      0.28      0.34       403\n",
      "          1       0.47      0.28      0.35       265\n",
      "\n",
      "avg / total       0.52      0.55      0.52      1384\n",
      "\n",
      "confusion matrix:\n",
      "[[568 103  45]\n",
      " [251 114  38]\n",
      " [141  49  75]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest classifiers\n",
    "results = []\n",
    "print('=' * 80)\n",
    "print(\"Random Forest Romney\")\n",
    "results.append(pipeline_function(RandomForestClassifier(n_estimators=100), \n",
    "                                 X_train_romney, X_test_romney, \n",
    "                                 y_train_romney, y_test_romney, \n",
    "                                 categories_romney))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "SGD Model Obama\n",
      "************************************************************\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='l1', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 0.156s\n",
      "test time:  0.000s\n",
      "accuracy:   0.564\n",
      "dimensionality: 2000\n",
      "density: 0.531333\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.61      0.60      0.60       488\n",
      "          0       0.52      0.52      0.52       457\n",
      "          1       0.56      0.58      0.57       398\n",
      "\n",
      "avg / total       0.56      0.56      0.56      1343\n",
      "\n",
      "confusion matrix:\n",
      "[[291 118  79]\n",
      " [119 237 101]\n",
      " [ 69  99 230]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train SGD Classifier\n",
    "results = []\n",
    "print('*' * 60)\n",
    "print(\"SGD Model Obama\")\n",
    "results.append(pipeline_function(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "                                           penalty='l1'), \n",
    "                                 X_train_obama, X_test_obama, \n",
    "                                 y_train_obama, y_test_obama, \n",
    "                                 categories_obama))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "SGD Model Romney\n",
      "************************************************************\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='l1', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 0.087s\n",
      "test time:  0.000s\n",
      "accuracy:   0.548\n",
      "dimensionality: 2000\n",
      "density: 0.522667\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.64      0.71      0.67       716\n",
      "          0       0.40      0.35      0.38       403\n",
      "          1       0.46      0.40      0.43       265\n",
      "\n",
      "avg / total       0.53      0.55      0.54      1384\n",
      "\n",
      "confusion matrix:\n",
      "[[510 143  63]\n",
      " [201 142  60]\n",
      " [ 92  67 106]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train SGD Classifier\n",
    "results = []\n",
    "print('*' * 60)\n",
    "print(\"SGD Model Romney\")\n",
    "results.append(pipeline_function(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "                                           penalty='l1'), \n",
    "                                 X_train_romney, X_test_romney, \n",
    "                                 y_train_romney, y_test_romney, \n",
    "                                 categories_romney))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "Linear SVM Model Obama\n",
      "************************************************************\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.001,\n",
      "     verbose=0)\n",
      "train time: 0.059s\n",
      "test time:  0.000s\n",
      "accuracy:   0.558\n",
      "dimensionality: 2000\n",
      "density: 1.000000\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.61      0.60      0.60       488\n",
      "          0       0.51      0.50      0.50       457\n",
      "          1       0.55      0.57      0.56       398\n",
      "\n",
      "avg / total       0.56      0.56      0.56      1343\n",
      "\n",
      "confusion matrix:\n",
      "[[294 119  75]\n",
      " [121 229 107]\n",
      " [ 69 103 226]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Linear SVM Classifier\n",
    "print('*' * 80)\n",
    "print(\"Linear SVM Model Obama\")\n",
    "results.append(pipeline_function(LinearSVC(loss='squared_hinge', penalty='l2',\n",
    "                                            dual=False, tol=1e-3),\n",
    "                                X_train_obama, X_test_obama, \n",
    "                                 y_train_obama, y_test_obama, \n",
    "                                 categories_obama))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "Linear SVM Model Romney\n",
      "************************************************************\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.001,\n",
      "     verbose=0)\n",
      "train time: 0.050s\n",
      "test time:  0.000s\n",
      "accuracy:   0.538\n",
      "dimensionality: 2000\n",
      "density: 1.000000\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.62      0.69      0.66       716\n",
      "          0       0.40      0.35      0.37       403\n",
      "          1       0.47      0.41      0.44       265\n",
      "\n",
      "avg / total       0.53      0.54      0.53      1384\n",
      "\n",
      "confusion matrix:\n",
      "[[494 154  68]\n",
      " [205 143  55]\n",
      " [ 92  65 108]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Linear SVM Classifier\n",
    "print('*' * 80)\n",
    "print(\"Linear SVM Model Romney\")\n",
    "results.append(pipeline_function(LinearSVC(loss='squared_hinge', penalty='l2',\n",
    "                                            dual=False, tol=1e-3),\n",
    "                                X_train_romney, X_test_romney, \n",
    "                                 y_train_romney, y_test_romney, \n",
    "                                 categories_romney))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Cross Validation (10 fold) on Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Linear SVM Obama\n",
      "[ 0.52966595  0.59747967  0.53881707  0.57758382  0.54466201  0.5723762\n",
      "  0.5755843   0.53059608  0.5498899   0.5426779 ]\n",
      "Accuracy: 0.56 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "tweet_random_df = tweet_df_obama.copy()\n",
    "len(tweet_random_df)\n",
    "for i in range(0, 100):\n",
    "    split1_df, split2_df = split_training_data(tweet_random_df, 50)\n",
    "    tweet_random_df = pd.concat([split1_df, split2_df])\n",
    "    \n",
    "X_kfcv_counts = count_vect.fit_transform(tweet_random_df['Anootated tweet'])\n",
    "X_kfcv = tfidf_transformer.fit_transform(X_kfcv_counts)\n",
    "Y_kfcv = tweet_random_df['Class']\n",
    "\n",
    "clf = LinearSVC(loss='squared_hinge', penalty='l2',dual=False, tol=1e-3)\n",
    "scores = cross_validation.cross_val_score(clf, X_kfcv, Y_kfcv, cv=10, scoring='f1_weighted')\n",
    "print(\"Cross Validation Linear SVM Obama\")\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Linear SVM Romney\n",
      "[ 0.53687145  0.56213105  0.57125204  0.56156171  0.5551547   0.54577134\n",
      "  0.55447597  0.5294919   0.55826338  0.56034268]\n",
      "Accuracy: 0.55 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "tweet_random_df = tweet_df_romney.copy()\n",
    "len(tweet_random_df)\n",
    "for i in range(0, 100):\n",
    "    split1_df, split2_df = split_training_data(tweet_random_df, 50)\n",
    "    tweet_random_df = pd.concat([split1_df, split2_df])\n",
    "    \n",
    "X_kfcv_counts = count_vect.fit_transform(tweet_random_df['Anootated tweet'])\n",
    "X_kfcv = tfidf_transformer.fit_transform(X_kfcv_counts)\n",
    "Y_kfcv = tweet_random_df['Class']\n",
    "\n",
    "clf = LinearSVC(loss='squared_hinge', penalty='l2',dual=False, tol=1e-3)\n",
    "scores = cross_validation.cross_val_score(clf, X_kfcv, Y_kfcv, cv=10, scoring='f1_weighted')\n",
    "print(\"Cross Validation Linear SVM Romney\")\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Cross Validation (10 fold) on Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Naive Bayes Obama\n",
      "[ 0.52412138  0.56025644  0.52397638  0.57085236  0.53627839  0.56958426\n",
      "  0.5631734   0.5357964   0.57170695  0.55743054]\n",
      "Accuracy: 0.55 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "tweet_random_df = tweet_df_obama.copy()\n",
    "for i in range(0, 100):\n",
    "    split1_df, split2_df = split_training_data(tweet_random_df, 50)\n",
    "    tweet_random_df = pd.concat([split1_df, split2_df])\n",
    "    \n",
    "X_kfcv_counts = count_vect.fit_transform(tweet_random_df['Anootated tweet'])\n",
    "X_kfcv = tfidf_transformer.fit_transform(X_kfcv_counts)\n",
    "Y_kfcv = tweet_random_df['Class']\n",
    "\n",
    "clf = MultinomialNB(alpha = 0.01)\n",
    "scores = cross_validation.cross_val_score(clf, X_kfcv, Y_kfcv, cv=10, scoring='f1_weighted')\n",
    "print(\"Cross Validation Naive Bayes Obama\")\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Naive Bayes Romney\n",
      "[ 0.56197955  0.53099091  0.55779734  0.57523544  0.52271181  0.54396701\n",
      "  0.51041333  0.57248649  0.52477631  0.55006461]\n",
      "Accuracy: 0.55 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "tweet_random_df = tweet_df_romney.copy()\n",
    "for i in range(0, 100):\n",
    "    split1_df, split2_df = split_training_data(tweet_random_df, 50)\n",
    "    tweet_random_df = pd.concat([split1_df, split2_df])\n",
    "    \n",
    "X_kfcv_counts = count_vect.fit_transform(tweet_random_df['Anootated tweet'])\n",
    "X_kfcv = tfidf_transformer.fit_transform(X_kfcv_counts)\n",
    "Y_kfcv = tweet_random_df['Class']\n",
    "\n",
    "clf = MultinomialNB(alpha = 0.01)\n",
    "scores = cross_validation.cross_val_score(clf, X_kfcv, Y_kfcv, cv=10, scoring='f1_weighted')\n",
    "print(\"Cross Validation Naive Bayes Romney\")\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Cross Validation (10 fold) on Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Random Forest Obama\n",
      "[ 0.54416288  0.57806726  0.57098955  0.58060935  0.57727401  0.59708174\n",
      "  0.55537649  0.55917022  0.55353935  0.52421015]\n",
      "Accuracy: 0.56 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "tweet_random_df = tweet_df_obama.copy()\n",
    "for i in range(0, 100):\n",
    "    split1_df, split2_df = split_training_data(tweet_random_df, 50)\n",
    "    tweet_random_df = pd.concat([split1_df, split2_df])\n",
    "    \n",
    "X_kfcv_counts = count_vect.fit_transform(tweet_random_df['Anootated tweet'])\n",
    "X_kfcv = tfidf_transformer.fit_transform(X_kfcv_counts)\n",
    "Y_kfcv = tweet_random_df['Class']\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "scores = cross_validation.cross_val_score(clf, X_kfcv, Y_kfcv, cv=10, scoring='f1_weighted')\n",
    "print(\"Cross Validation Random Forest Obama\")\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Random Forest Romney\n",
      "[ 0.51715193  0.59279902  0.55210046  0.50244742  0.54871538  0.55004637\n",
      "  0.54856987  0.56277669  0.52764518  0.51241765]\n",
      "Accuracy: 0.54 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "tweet_random_df = tweet_df_romney.copy()\n",
    "for i in range(0, 100):\n",
    "    split1_df, split2_df = split_training_data(tweet_random_df, 50)\n",
    "    tweet_random_df = pd.concat([split1_df, split2_df])\n",
    "    \n",
    "X_kfcv_counts = count_vect.fit_transform(tweet_random_df['Anootated tweet'])\n",
    "X_kfcv = tfidf_transformer.fit_transform(X_kfcv_counts)\n",
    "Y_kfcv = tweet_random_df['Class']\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "scores = cross_validation.cross_val_score(clf, X_kfcv, Y_kfcv, cv=10, scoring='f1_weighted')\n",
    "print(\"Cross Validation Random Forest Romney\")\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation (10 fold) on Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Logistic Regression Obama\n",
      "[ 0.60710851  0.57358587  0.54813402  0.55599074  0.57758801  0.57621341\n",
      "  0.56733556  0.58392341  0.56336149  0.5712577 ]\n",
      "Accuracy: 0.57 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "tweet_random_df = tweet_df_obama.copy()\n",
    "for i in range(0, 100):\n",
    "    split1_df, split2_df = split_training_data(tweet_random_df, 50)\n",
    "    tweet_random_df = pd.concat([split1_df, split2_df])\n",
    "    \n",
    "X_kfcv_counts = count_vect.fit_transform(tweet_random_df['Anootated tweet'])\n",
    "X_kfcv = tfidf_transformer.fit_transform(X_kfcv_counts)\n",
    "Y_kfcv = tweet_random_df['Class']\n",
    "\n",
    "clf = SGDClassifier(alpha=.0001, n_iter=50, penalty='l1')\n",
    "scores = cross_validation.cross_val_score(clf, X_kfcv, Y_kfcv, cv=10, scoring='f1_weighted')\n",
    "print(\"Cross Validation Logistic Regression Obama\")\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Logistic Regression Romney\n",
      "[ 0.49903378  0.5644837   0.52795483  0.55739991  0.5647148   0.53822631\n",
      "  0.5645592   0.59904538  0.52530778  0.50146229]\n",
      "Accuracy: 0.54 (+/- 0.06)\n"
     ]
    }
   ],
   "source": [
    "tweet_random_df = tweet_df_romney.copy()\n",
    "for i in range(0, 100):\n",
    "    split1_df, split2_df = split_training_data(tweet_random_df, 50)\n",
    "    tweet_random_df = pd.concat([split1_df, split2_df])\n",
    "    \n",
    "X_kfcv_counts = count_vect.fit_transform(tweet_random_df['Anootated tweet'])\n",
    "X_kfcv = tfidf_transformer.fit_transform(X_kfcv_counts)\n",
    "Y_kfcv = tweet_random_df['Class']\n",
    "\n",
    "clf = SGDClassifier(alpha=.0001, n_iter=50, penalty='l1')\n",
    "scores = cross_validation.cross_val_score(clf, X_kfcv, Y_kfcv, cv=10, scoring='f1_weighted')\n",
    "print(\"Cross Validation Logistic Regression Romney\")\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
