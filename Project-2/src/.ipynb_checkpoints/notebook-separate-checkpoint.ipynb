{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from time import time\n",
    "import string\n",
    "import itertools\n",
    "from html import unescape\n",
    "import preprocessor as p\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "from sklearn import cross_validation\n",
    "from sklearn import svm\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data from Excel file and create data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_excel_file(filename, sheetname):\n",
    "    return pd.read_excel(filename, sheetname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_unwanted_columns(tweet_df):\n",
    "    del tweet_df['date']\n",
    "    del tweet_df['time']\n",
    "    return tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_from_input_data (filename):\n",
    "    tweet_df_obama = read_excel_file(filename, 0)\n",
    "    tweet_df_romney = read_excel_file(filename, 1)\n",
    "    # tweet_df_obama = remove_unwanted_columns(tweet_df_obama)\n",
    "    # tweet_df_romney = remove_unwanted_columns(tweet_df_romney)\n",
    "    \n",
    "    tweet_df_obama['Class'] = tweet_df_obama['Class'].astype('str').map(lambda x: x.lstrip(' ').rstrip(' '))\n",
    "    tweet_df_obama['Class'] = tweet_df_obama['Class'].astype('str').map(lambda x: x.replace('!!!!', ''))\n",
    "    \n",
    "    tweet_data_df_obama = tweet_df_obama.loc[tweet_df_obama.Class=='1'].append(tweet_df_obama.loc[tweet_df_obama.Class=='-1']).append(tweet_df_obama.loc[tweet_df_obama.Class=='0'])\n",
    "    \n",
    "    tweet_data_df_obama.dropna(inplace = True)\n",
    "    \n",
    "    tweet_df_romney['Class'] = tweet_df_romney['Class'].astype('str').map(lambda x: x.lstrip(' ').rstrip(' '))\n",
    "    tweet_df_romney['Class'] = tweet_df_romney['Class'].astype('str').map(lambda x: x.replace('!!!!', ''))\n",
    "    \n",
    "    tweet_data_df_romney = tweet_df_romney.loc[tweet_df_romney.Class=='1'].append(tweet_df_romney.loc[tweet_df_romney.Class=='-1']).append(tweet_df_romney.loc[tweet_df_romney.Class=='0'])\n",
    "    \n",
    "    tweet_data_df_romney.dropna(inplace = True)\n",
    "    \n",
    "    return tweet_data_df_obama, tweet_data_df_romney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_training_data(df, train_data_prcnt):\n",
    "    msk = np.random.rand(len(df)) < train_data_prcnt/100\n",
    "    train = df[msk]\n",
    "    test = df[~msk]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a8bab8d00310>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtweet_df_obama\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet_df_romney\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_from_input_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training-Obama-Romney-tweets.xlsx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mexclude\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-5f3305c41e7d>\u001b[0m in \u001b[0;36mread_from_input_data\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtweet_df_obama\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_excel_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtweet_df_romney\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_excel_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtweet_df_obama\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_unwanted_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet_df_obama\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtweet_df_romney\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_unwanted_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet_df_romney\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-da9c0a0518e5>\u001b[0m in \u001b[0;36mremove_unwanted_columns\u001b[0;34m(tweet_df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mremove_unwanted_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mdel\u001b[0m \u001b[0mtweet_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mtweet_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtweet_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kushagrathapar/anaconda/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__delitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1342\u001b[0m             \u001b[0;31m# there was no match, this call should raise the appropriate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m             \u001b[0;31m# exception:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m         \u001b[0;31m# delete from the caches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kushagrathapar/anaconda/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mdelete\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   3266\u001b[0m         \u001b[0mDelete\u001b[0m \u001b[0mselected\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnon\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mplace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3267\u001b[0m         \"\"\"\n\u001b[0;32m-> 3268\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3270\u001b[0m         \u001b[0mis_deleted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kushagrathapar/anaconda/lib/python3.5/site-packages/pandas/core/index.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1757\u001b[0m                                  'backfill or nearest lookups')\n\u001b[1;32m   1758\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1759\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         indexer = self.get_indexer([key], method=method,\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3979)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3843)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12265)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12216)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'date'"
     ]
    }
   ],
   "source": [
    "tweet_df_obama, tweet_df_romney = read_from_input_data(\"training-Obama-Romney-tweets.xlsx\")\n",
    "exclude = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama Data\n",
      "-1 : 1968\n",
      " 1 : 1679\n",
      " 0 : 1977\n",
      "\n",
      "Romney Data\n",
      "-1 : 2893\n",
      " 1 : 1075\n",
      " 0 : 1680\n"
     ]
    }
   ],
   "source": [
    "print(\"Obama Data\")\n",
    "print(\"-1 : \" + str(len(tweet_df_obama.loc[tweet_df_obama.Class=='-1'])))\n",
    "print(\" 1 : \" + str(len(tweet_df_obama.loc[tweet_df_obama.Class=='1'])))\n",
    "print(\" 0 : \" + str(len(tweet_df_obama.loc[tweet_df_obama.Class=='0'])))\n",
    "\n",
    "print(\"\\nRomney Data\")\n",
    "\n",
    "print(\"-1 : \" + str(len(tweet_df_romney.loc[tweet_df_romney.Class=='-1'])))\n",
    "print(\" 1 : \" + str(len(tweet_df_romney.loc[tweet_df_romney.Class=='1'])))\n",
    "print(\" 0 : \" + str(len(tweet_df_romney.loc[tweet_df_romney.Class=='0'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_tweet_text(text):\n",
    "    \n",
    "    if not pd.isnull(text):\n",
    "        # Remove html escape characters and replace with their meaning\n",
    "        text = unescape(text)\n",
    "        # Decode tweet to utf-8 format\n",
    "\n",
    "        text = text.encode(\"ascii\", \"ignore\").decode(\"utf8\")\n",
    "\n",
    "        # Clean data using tweet preprocessor and convert to lower case\n",
    "        text = str.lower(p.clean(text))\n",
    "\n",
    "        # Remove characters\n",
    "        text = text.replace(\"<e>\", \"\")\n",
    "        text = text.replace(\"</e>\", \"\")\n",
    "        text = text.replace(\"<a>\", \"\")\n",
    "        text = text.replace(\"</a>\", \"\")\n",
    "\n",
    "        # Remove multiple repetition of a character in word\n",
    "        text = ''.join(''.join(s)[:2] for _, s in itertools.groupby(text))\n",
    "\n",
    "        # Remove punctuation\n",
    "        text = ''.join(ch for ch in text if ch not in exclude)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweet_df_obama['Anootated tweet'] = tweet_df_obama['Anootated tweet'].map(clean_tweet_text)\n",
    "tweet_df_romney['Anootated tweet'] = tweet_df_romney['Anootated tweet'].map(clean_tweet_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slipt data into train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4256\n",
      "1368\n",
      "4276\n",
      "1372\n"
     ]
    }
   ],
   "source": [
    "tweet_random_df_obama = tweet_df_obama.copy()\n",
    "\n",
    "for i in range(0, 500):\n",
    "    split1_df, split2_df = split_training_data(tweet_random_df_obama, 50)\n",
    "    tweet_random_df_obama = pd.concat([split1_df, split2_df])\n",
    "\n",
    "train_df_obama, test_df_obama = split_training_data(tweet_random_df_obama, 75)\n",
    "\n",
    "print(len(train_df_obama))\n",
    "print(len(test_df_obama))\n",
    "\n",
    "tweet_random_df_romney = tweet_df_romney.copy()\n",
    "\n",
    "for i in range(0, 500):\n",
    "    split1_df, split2_df = split_training_data(tweet_random_df_romney, 50)\n",
    "    tweet_random_df_romney = pd.concat([split1_df, split2_df])\n",
    "\n",
    "train_df_romney, test_df_romney = split_training_data(tweet_random_df_romney, 75)\n",
    "\n",
    "print(len(train_df_romney))\n",
    "print(len(test_df_romney))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Bag of Words model to sparce vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(stop_words='english', max_features=2000 )\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english', max_features=2000)\n",
    "hash_vectorizer = HashingVectorizer(stop_words='english', non_negative=True, n_features = 2000)\n",
    "tfidf_transformer = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_counts_obama = count_vect.fit_transform(train_df_obama['Anootated tweet'])\n",
    "X_test_counts_obama = count_vect.transform(test_df_obama['Anootated tweet'])\n",
    "\n",
    "X_train_obama = tfidf_transformer.fit_transform(X_train_counts_obama)\n",
    "X_test_obama = tfidf_transformer.transform(X_test_counts_obama)\n",
    "\n",
    "y_train_obama = train_df_obama['Class']\n",
    "y_test_obama = test_df_obama['Class']\n",
    "\n",
    "\n",
    "X_train_counts_romney = count_vect.fit_transform(train_df_romney['Anootated tweet'])\n",
    "X_test_counts_romney = count_vect.transform(test_df_romney['Anootated tweet'])\n",
    "\n",
    "X_train_romney = tfidf_transformer.fit_transform(X_train_counts_romney)\n",
    "X_test_romney = tfidf_transformer.transform(X_test_counts_romney)\n",
    "\n",
    "y_train_romney = train_df_romney['Class']\n",
    "y_test_romney = test_df_romney['Class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trim(s):\n",
    "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
    "    return s if len(s) <= 80 else s[:77] + \"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Classification function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pipeline_function(clf, X_train, X_test, y_train, y_test, categories):\n",
    "    print('*' * 60)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "\n",
    "#         if feature_names is not None:\n",
    "#             print(\"top 10 keywords per class:\")\n",
    "#             for i, category in enumerate(categories):\n",
    "#                 top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "#                 print(trim(\"%s: %s\"\n",
    "#                       % (category, \" \".join(feature_names[top10]))))\n",
    "#         print()\n",
    "\n",
    "    print(\"classification report:\")\n",
    "    print(metrics.classification_report(y_test, pred,\n",
    "                                        target_names=categories))\n",
    "\n",
    "    print(\"confusion matrix:\")\n",
    "    print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    return clf_descr, score, train_time, test_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "Naive Bayes Obama\n",
      "************************************************************\n",
      "Training: \n",
      "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "train time: 0.013s\n",
      "test time:  0.000s\n",
      "accuracy:   0.531\n",
      "dimensionality: 2000\n",
      "density: 1.000000\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.52      0.60      0.56       459\n",
      "          0       0.50      0.43      0.47       483\n",
      "          1       0.57      0.57      0.57       426\n",
      "\n",
      "avg / total       0.53      0.53      0.53      1368\n",
      "\n",
      "confusion matrix:\n",
      "[[274 117  68]\n",
      " [160 210 113]\n",
      " [ 90  93 243]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "categories_obama = np.unique(y_train_obama.values)\n",
    "# Train sparse Naive Bayes classifiers\n",
    "print('*' * 60)\n",
    "print(\"Naive Bayes Obama\")\n",
    "results.append(pipeline_function(MultinomialNB(alpha=.01), \n",
    "                                 X_train_obama, X_test_obama, \n",
    "                                 y_train_obama, y_test_obama, \n",
    "                                 categories_obama))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "Naive Bayes Romney\n",
      "************************************************************\n",
      "Training: \n",
      "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "train time: 0.013s\n",
      "test time:  0.000s\n",
      "accuracy:   0.579\n",
      "dimensionality: 2000\n",
      "density: 1.000000\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.64      0.80      0.71       721\n",
      "          0       0.45      0.32      0.37       399\n",
      "          1       0.50      0.35      0.41       252\n",
      "\n",
      "avg / total       0.56      0.58      0.56      1372\n",
      "\n",
      "confusion matrix:\n",
      "[[578 106  37]\n",
      " [219 128  52]\n",
      " [112  51  89]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "categories_romney = np.unique(y_train_romney.values)\n",
    "# Train sparse Naive Bayes classifiers\n",
    "print('*' * 60)\n",
    "print(\"Naive Bayes Romney\")\n",
    "results.append(pipeline_function(MultinomialNB(alpha=.01), \n",
    "                                 X_train_romney, X_test_romney, \n",
    "                                 y_train_romney, y_test_romney, \n",
    "                                 categories_romney))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbour Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "k Nearest Neighbour Obama\n",
      "************************************************************\n",
      "Training: \n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "train time: 0.005s\n",
      "test time:  0.447s\n",
      "accuracy:   0.444\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.60      0.15      0.24       459\n",
      "          0       0.41      0.59      0.48       483\n",
      "          1       0.45      0.60      0.51       426\n",
      "\n",
      "avg / total       0.49      0.44      0.41      1368\n",
      "\n",
      "confusion matrix:\n",
      "[[ 68 248 143]\n",
      " [ 34 285 164]\n",
      " [ 12 160 254]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train k-Nearest Neighbour classifiers\n",
    "results = []\n",
    "print('*' * 60)\n",
    "print(\"k Nearest Neighbour Obama\")\n",
    "results.append(pipeline_function(KNeighborsClassifier(n_neighbors=10, n_jobs = -1), \n",
    "                                 X_train_obama, X_test_obama, \n",
    "                                 y_train_obama, y_test_obama, \n",
    "                                 categories_obama))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "k Nearest Neighbour Romney\n",
      "************************************************************\n",
      "Training: \n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "train time: 0.005s\n",
      "test time:  0.469s\n",
      "accuracy:   0.384\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.69      0.19      0.30       721\n",
      "          0       0.31      0.88      0.46       399\n",
      "          1       0.73      0.15      0.24       252\n",
      "\n",
      "avg / total       0.59      0.38      0.34      1372\n",
      "\n",
      "confusion matrix:\n",
      "[[140 575   6]\n",
      " [ 41 350   8]\n",
      " [ 21 194  37]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "print('*' * 60)\n",
    "print(\"k Nearest Neighbour Romney\")\n",
    "results.append(pipeline_function(KNeighborsClassifier(n_neighbors=10, n_jobs = -1), \n",
    "                                 X_train_romney, X_test_romney, \n",
    "                                 y_train_romney, y_test_romney, \n",
    "                                 categories_romney))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Random Forest Obama\n",
      "************************************************************\n",
      "Training: \n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "train time: 2.494s\n",
      "test time:  0.085s\n",
      "accuracy:   0.561\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.57      0.55      0.56       459\n",
      "          0       0.53      0.57      0.55       483\n",
      "          1       0.59      0.56      0.57       426\n",
      "\n",
      "avg / total       0.56      0.56      0.56      1368\n",
      "\n",
      "confusion matrix:\n",
      "[[254 128  77]\n",
      " [118 277  88]\n",
      " [ 75 114 237]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest classifiers\n",
    "results = []\n",
    "print('=' * 80)\n",
    "print(\"Random Forest Obama\")\n",
    "results.append(pipeline_function(RandomForestClassifier(n_estimators=100), \n",
    "                                 X_train_obama, X_test_obama, \n",
    "                                 y_train_obama, y_test_obama, \n",
    "                                 categories_obama))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Random Forest Romney\n",
      "************************************************************\n",
      "Training: \n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "train time: 2.824s\n",
      "test time:  0.095s\n",
      "accuracy:   0.574\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.62      0.79      0.70       721\n",
      "          0       0.46      0.33      0.38       399\n",
      "          1       0.52      0.35      0.42       252\n",
      "\n",
      "avg / total       0.55      0.57      0.55      1372\n",
      "\n",
      "confusion matrix:\n",
      "[[569 116  36]\n",
      " [223 131  45]\n",
      " [124  40  88]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest classifiers\n",
    "results = []\n",
    "print('=' * 80)\n",
    "print(\"Random Forest Romney\")\n",
    "results.append(pipeline_function(RandomForestClassifier(n_estimators=100), \n",
    "                                 X_train_romney, X_test_romney, \n",
    "                                 y_train_romney, y_test_romney, \n",
    "                                 categories_romney))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "SGD Model Obama\n",
      "************************************************************\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='l1', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 0.123s\n",
      "test time:  0.000s\n",
      "accuracy:   0.535\n",
      "dimensionality: 2000\n",
      "density: 0.536000\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.53      0.56      0.54       459\n",
      "          0       0.51      0.48      0.49       483\n",
      "          1       0.57      0.58      0.57       426\n",
      "\n",
      "avg / total       0.53      0.54      0.53      1368\n",
      "\n",
      "confusion matrix:\n",
      "[[255 128  76]\n",
      " [140 230 113]\n",
      " [ 83  96 247]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train SGD Classifier\n",
    "results = []\n",
    "print('*' * 60)\n",
    "print(\"SGD Model Obama\")\n",
    "results.append(pipeline_function(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "                                           penalty='l1'), \n",
    "                                 X_train_obama, X_test_obama, \n",
    "                                 y_train_obama, y_test_obama, \n",
    "                                 categories_obama))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "SGD Model Romney\n",
      "************************************************************\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='l1', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 0.085s\n",
      "test time:  0.000s\n",
      "accuracy:   0.558\n",
      "dimensionality: 2000\n",
      "density: 0.515000\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.64      0.71      0.67       721\n",
      "          0       0.41      0.37      0.39       399\n",
      "          1       0.50      0.42      0.46       252\n",
      "\n",
      "avg / total       0.55      0.56      0.55      1372\n",
      "\n",
      "confusion matrix:\n",
      "[[510 158  53]\n",
      " [197 148  54]\n",
      " [ 86  59 107]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train SGD Classifier\n",
    "results = []\n",
    "print('*' * 60)\n",
    "print(\"SGD Model Romney\")\n",
    "results.append(pipeline_function(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "                                           penalty='l1'), \n",
    "                                 X_train_romney, X_test_romney, \n",
    "                                 y_train_romney, y_test_romney, \n",
    "                                 categories_romney))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "Linear SVM Model Obama\n",
      "************************************************************\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.001,\n",
      "     verbose=0)\n",
      "train time: 0.048s\n",
      "test time:  0.000s\n",
      "accuracy:   0.543\n",
      "dimensionality: 2000\n",
      "density: 1.000000\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.53      0.58      0.55       459\n",
      "          0       0.53      0.47      0.50       483\n",
      "          1       0.58      0.58      0.58       426\n",
      "\n",
      "avg / total       0.54      0.54      0.54      1368\n",
      "\n",
      "confusion matrix:\n",
      "[[268 116  75]\n",
      " [149 229 105]\n",
      " [ 91  89 246]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Linear SVM Classifier\n",
    "print('*' * 80)\n",
    "print(\"Linear SVM Model Obama\")\n",
    "results.append(pipeline_function(LinearSVC(loss='squared_hinge', penalty='l2',\n",
    "                                            dual=False, tol=1e-3),\n",
    "                                X_train_obama, X_test_obama, \n",
    "                                 y_train_obama, y_test_obama, \n",
    "                                 categories_obama))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "Linear SVM Model Romney\n",
      "************************************************************\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.001,\n",
      "     verbose=0)\n",
      "train time: 0.045s\n",
      "test time:  0.000s\n",
      "accuracy:   0.540\n",
      "dimensionality: 2000\n",
      "density: 1.000000\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.64      0.69      0.66       721\n",
      "          0       0.39      0.36      0.38       399\n",
      "          1       0.44      0.40      0.42       252\n",
      "\n",
      "avg / total       0.53      0.54      0.53      1372\n",
      "\n",
      "confusion matrix:\n",
      "[[496 160  65]\n",
      " [191 144  64]\n",
      " [ 89  62 101]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Linear SVM Classifier\n",
    "print('*' * 80)\n",
    "print(\"Linear SVM Model Romney\")\n",
    "results.append(pipeline_function(LinearSVC(loss='squared_hinge', penalty='l2',\n",
    "                                            dual=False, tol=1e-3),\n",
    "                                X_train_romney, X_test_romney, \n",
    "                                 y_train_romney, y_test_romney, \n",
    "                                 categories_romney))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Cross Validation (10 fold) on Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Linear SVM Obama\n",
      "[ 0.52966595  0.59747967  0.53881707  0.57758382  0.54466201  0.5723762\n",
      "  0.5755843   0.53059608  0.5498899   0.5426779 ]\n",
      "Accuracy: 0.56 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "tweet_random_df = tweet_df_obama.copy()\n",
    "len(tweet_random_df)\n",
    "for i in range(0, 100):\n",
    "    split1_df, split2_df = split_training_data(tweet_random_df, 50)\n",
    "    tweet_random_df = pd.concat([split1_df, split2_df])\n",
    "    \n",
    "X_kfcv_counts = count_vect.fit_transform(tweet_random_df['Anootated tweet'])\n",
    "X_kfcv = tfidf_transformer.fit_transform(X_kfcv_counts)\n",
    "Y_kfcv = tweet_random_df['Class']\n",
    "\n",
    "clf = LinearSVC(loss='squared_hinge', penalty='l2',dual=False, tol=1e-3)\n",
    "scores = cross_validation.cross_val_score(clf, X_kfcv, Y_kfcv, cv=10, scoring='f1_weighted')\n",
    "print(\"Cross Validation Linear SVM Obama\")\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Linear SVM Romney\n",
      "[ 0.53687145  0.56213105  0.57125204  0.56156171  0.5551547   0.54577134\n",
      "  0.55447597  0.5294919   0.55826338  0.56034268]\n",
      "Accuracy: 0.55 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "tweet_random_df = tweet_df_romney.copy()\n",
    "len(tweet_random_df)\n",
    "for i in range(0, 100):\n",
    "    split1_df, split2_df = split_training_data(tweet_random_df, 50)\n",
    "    tweet_random_df = pd.concat([split1_df, split2_df])\n",
    "    \n",
    "X_kfcv_counts = count_vect.fit_transform(tweet_random_df['Anootated tweet'])\n",
    "X_kfcv = tfidf_transformer.fit_transform(X_kfcv_counts)\n",
    "Y_kfcv = tweet_random_df['Class']\n",
    "\n",
    "clf = LinearSVC(loss='squared_hinge', penalty='l2',dual=False, tol=1e-3)\n",
    "scores = cross_validation.cross_val_score(clf, X_kfcv, Y_kfcv, cv=10, scoring='f1_weighted')\n",
    "print(\"Cross Validation Linear SVM Romney\")\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Cross Validation (10 fold) on Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Naive Bayes Obama\n",
      "[ 0.52412138  0.56025644  0.52397638  0.57085236  0.53627839  0.56958426\n",
      "  0.5631734   0.5357964   0.57170695  0.55743054]\n",
      "Accuracy: 0.55 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "tweet_random_df = tweet_df_obama.copy()\n",
    "for i in range(0, 100):\n",
    "    split1_df, split2_df = split_training_data(tweet_random_df, 50)\n",
    "    tweet_random_df = pd.concat([split1_df, split2_df])\n",
    "    \n",
    "X_kfcv_counts = count_vect.fit_transform(tweet_random_df['Anootated tweet'])\n",
    "X_kfcv = tfidf_transformer.fit_transform(X_kfcv_counts)\n",
    "Y_kfcv = tweet_random_df['Class']\n",
    "\n",
    "clf = MultinomialNB(alpha = 0.01)\n",
    "scores = cross_validation.cross_val_score(clf, X_kfcv, Y_kfcv, cv=10, scoring='f1_weighted')\n",
    "print(\"Cross Validation Naive Bayes Obama\")\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Naive Bayes Romney\n",
      "[ 0.56197955  0.53099091  0.55779734  0.57523544  0.52271181  0.54396701\n",
      "  0.51041333  0.57248649  0.52477631  0.55006461]\n",
      "Accuracy: 0.55 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "tweet_random_df = tweet_df_romney.copy()\n",
    "for i in range(0, 100):\n",
    "    split1_df, split2_df = split_training_data(tweet_random_df, 50)\n",
    "    tweet_random_df = pd.concat([split1_df, split2_df])\n",
    "    \n",
    "X_kfcv_counts = count_vect.fit_transform(tweet_random_df['Anootated tweet'])\n",
    "X_kfcv = tfidf_transformer.fit_transform(X_kfcv_counts)\n",
    "Y_kfcv = tweet_random_df['Class']\n",
    "\n",
    "clf = MultinomialNB(alpha = 0.01)\n",
    "scores = cross_validation.cross_val_score(clf, X_kfcv, Y_kfcv, cv=10, scoring='f1_weighted')\n",
    "print(\"Cross Validation Naive Bayes Romney\")\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Cross Validation (10 fold) on Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Random Forest Obama\n",
      "[ 0.54416288  0.57806726  0.57098955  0.58060935  0.57727401  0.59708174\n",
      "  0.55537649  0.55917022  0.55353935  0.52421015]\n",
      "Accuracy: 0.56 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "tweet_random_df = tweet_df_obama.copy()\n",
    "for i in range(0, 100):\n",
    "    split1_df, split2_df = split_training_data(tweet_random_df, 50)\n",
    "    tweet_random_df = pd.concat([split1_df, split2_df])\n",
    "    \n",
    "X_kfcv_counts = count_vect.fit_transform(tweet_random_df['Anootated tweet'])\n",
    "X_kfcv = tfidf_transformer.fit_transform(X_kfcv_counts)\n",
    "Y_kfcv = tweet_random_df['Class']\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "scores = cross_validation.cross_val_score(clf, X_kfcv, Y_kfcv, cv=10, scoring='f1_weighted')\n",
    "print(\"Cross Validation Random Forest Obama\")\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Random Forest Romney\n",
      "[ 0.51715193  0.59279902  0.55210046  0.50244742  0.54871538  0.55004637\n",
      "  0.54856987  0.56277669  0.52764518  0.51241765]\n",
      "Accuracy: 0.54 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "tweet_random_df = tweet_df_romney.copy()\n",
    "for i in range(0, 100):\n",
    "    split1_df, split2_df = split_training_data(tweet_random_df, 50)\n",
    "    tweet_random_df = pd.concat([split1_df, split2_df])\n",
    "    \n",
    "X_kfcv_counts = count_vect.fit_transform(tweet_random_df['Anootated tweet'])\n",
    "X_kfcv = tfidf_transformer.fit_transform(X_kfcv_counts)\n",
    "Y_kfcv = tweet_random_df['Class']\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "scores = cross_validation.cross_val_score(clf, X_kfcv, Y_kfcv, cv=10, scoring='f1_weighted')\n",
    "print(\"Cross Validation Random Forest Romney\")\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation (10 fold) on Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Logistic Regression Obama\n",
      "[ 0.60710851  0.57358587  0.54813402  0.55599074  0.57758801  0.57621341\n",
      "  0.56733556  0.58392341  0.56336149  0.5712577 ]\n",
      "Accuracy: 0.57 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "tweet_random_df = tweet_df_obama.copy()\n",
    "for i in range(0, 100):\n",
    "    split1_df, split2_df = split_training_data(tweet_random_df, 50)\n",
    "    tweet_random_df = pd.concat([split1_df, split2_df])\n",
    "    \n",
    "X_kfcv_counts = count_vect.fit_transform(tweet_random_df['Anootated tweet'])\n",
    "X_kfcv = tfidf_transformer.fit_transform(X_kfcv_counts)\n",
    "Y_kfcv = tweet_random_df['Class']\n",
    "\n",
    "clf = SGDClassifier(alpha=.0001, n_iter=50, penalty='l1')\n",
    "scores = cross_validation.cross_val_score(clf, X_kfcv, Y_kfcv, cv=10, scoring='f1_weighted')\n",
    "print(\"Cross Validation Logistic Regression Obama\")\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Logistic Regression Romney\n",
      "[ 0.49903378  0.5644837   0.52795483  0.55739991  0.5647148   0.53822631\n",
      "  0.5645592   0.59904538  0.52530778  0.50146229]\n",
      "Accuracy: 0.54 (+/- 0.06)\n"
     ]
    }
   ],
   "source": [
    "tweet_random_df = tweet_df_romney.copy()\n",
    "for i in range(0, 100):\n",
    "    split1_df, split2_df = split_training_data(tweet_random_df, 50)\n",
    "    tweet_random_df = pd.concat([split1_df, split2_df])\n",
    "    \n",
    "X_kfcv_counts = count_vect.fit_transform(tweet_random_df['Anootated tweet'])\n",
    "X_kfcv = tfidf_transformer.fit_transform(X_kfcv_counts)\n",
    "Y_kfcv = tweet_random_df['Class']\n",
    "\n",
    "clf = SGDClassifier(alpha=.0001, n_iter=50, penalty='l1')\n",
    "scores = cross_validation.cross_val_score(clf, X_kfcv, Y_kfcv, cv=10, scoring='f1_weighted')\n",
    "print(\"Cross Validation Logistic Regression Romney\")\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
